{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "I wanted a numpy database to test and prototype this kit. I mean I have GPDK45nm but it has very few data points to see any trends properly. [NCSU's FreePDK45](https://eda.ncsu.edu/freepdk/freepdk45/) on the other hand has even corner models! But the problem is that they are HSPICE and since I have primarily written my importer function for Cadence Spectre I did not consider FreePDK45 as an option.\n",
    "\n",
    "Luckily [Mohamed Watfa's gmid toolkit in python](https://github.com/medwatt/gmid) recently published an [update](https://github.com/medwatt/gmid/commit/a5f52b4c1070470944da977b1d8a6bee99118a3c) which finally removed pyspice dependency which now enables me to seamlessly use the [LookupTableGenerator](https://github.com/medwatt/gmid#generating-a-lookup-table). Now I need to convert it to a format so that my library can read it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need to have the gmid toolkit installed and the model file at the correct location.\n",
    "\n",
    "# from main.lookup_table_generator import LookupTableGenerator\n",
    "# import numpy as np\n",
    "# l_sweep_initial = np.array([45e-9])\n",
    "# l_sweep_small  = np.arange(100e-9,1e-6,100e-9) # excluded the last value.\n",
    "# l_sweep_large  = np.arange(1e-6,11e-6,1e-6) # excludes the last value\n",
    "# l_sweep = np.concatenate((l_sweep_initial,l_sweep_small,l_sweep_large))\n",
    "# lengths = l_sweep.tolist()\n",
    "\n",
    "# obj = LookupTableGenerator(\n",
    "#     description=\"freepdk 45nm ngspice\",\n",
    "#     simulator=\"ngspice\",\n",
    "#     model_paths=[\n",
    "#         \"./models/models_ss/NMOS_VTH.inc\",\n",
    "#         \"./models/models_ss/PMOS_VTH.inc\",\n",
    "#         ],\n",
    "#     model_names={\n",
    "#         \"nmos\": \"NMOS_VTH\",\n",
    "#         \"pmos\": \"PMOS_VTH\",\n",
    "#     },\n",
    "#     temp=25,\n",
    "#     vsb=(0, 0.5, 0.1),\n",
    "#     vgs=(0, 1.0, 0.01),\n",
    "#     vds=(0, 1.0, 0.01),\n",
    "#     width=10e-6,\n",
    "#     lengths=lengths,\n",
    "# )\n",
    "# obj.build(\"./freepdk45/original_npy/ss.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing\n",
    "\n",
    "Surprisingly the Lookup Table (LUT) generation was very fastest I have seen. Now to make the structure compliant with my `.npy` structure I am doing post processing.\n",
    "Hopefully I don't have to make any major changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "# Append the path of your library to the system path\n",
    "sys.path.append(os.path.abspath(\"../../\"))\n",
    "from analog_daddy.look_up import look_up\n",
    "from analog_daddy.utils import pretty_print_structure, describe_structure\n",
    "from analog_daddy.conf import * # import all the config variables\n",
    "from analog_daddy.importer import lists_to_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGINAL_DATABASE_PATH = \"../../ignored_folder/databases/freepdk45/original_npy/nom_25.npy\"\n",
    "FINAL_DATABASE_PATH = \"../../ignored_folder/databases/freepdk45/NPY/nom_25.npy\"\n",
    "data = lists_to_arrays(np.load(ORIGINAL_DATABASE_PATH, allow_pickle=True).item())\n",
    "data['corner'] = 'nom'\n",
    "data['temperature'] = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print_structure(describe_structure(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nesting the lengths and width to be accessed without parent structure\n",
    "# also renaming keys to match the defaults.\n",
    "data['nmos']['length'] = data['l']\n",
    "data['pmos']['length'] = data['l']\n",
    "data['nmos']['w'] = data['w']\n",
    "data['pmos']['w'] = data['w']\n",
    "\n",
    "# renaming vgs, vds and vsb to match the defaults.\n",
    "data['nmos']['gs'] = data['nmos']['vgs']\n",
    "data['nmos']['ds'] = data['nmos']['vds']\n",
    "data['nmos']['sb'] = data['nmos']['vsb']\n",
    "data['pmos']['gs'] = data['pmos']['vgs']\n",
    "data['pmos']['ds'] = data['pmos']['vds']\n",
    "data['pmos']['sb'] = data['pmos']['vsb']\n",
    "\n",
    "del data['l']\n",
    "del data['w']\n",
    "del data['nmos']['vgs']\n",
    "del data['nmos']['vds']\n",
    "del data['nmos']['vsb']\n",
    "del data['pmos']['vgs']\n",
    "del data['pmos']['vds']\n",
    "del data['pmos']['vsb']\n",
    "\n",
    "data['info'] = data['description']\n",
    "del data['description']\n",
    "del data['parameter_names']\n",
    "del data['nmos']['model_name']\n",
    "del data['pmos']['model_name']\n",
    "data['nmos_vth'] = data['nmos']\n",
    "data['pmos_vth'] = data['pmos']\n",
    "del data['nmos']\n",
    "del data['pmos']\n",
    "\n",
    "for key in data['pmos_vth'].keys():\n",
    "    data['pmos_vth'][key] = abs(data['pmos_vth'][key])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restructure the array dimensions\n",
    "# Original structure seems to be\n",
    "# cgg[length][sb][gs][ds]\n",
    "# I need it to be\n",
    "# cgg[ds][gs][length][sb]\n",
    "# thus  transposed_array = original_array.transpose(3, 2, 0, 1)\n",
    "\n",
    "def transpose_4d_arrays(d):\n",
    "    \"\"\"\n",
    "    Recursively transposes 4D arrays within a nested dictionary.\n",
    "    \"\"\"\n",
    "    for key, value in d.items():\n",
    "        if isinstance(value, np.ndarray) and value.ndim == 4:\n",
    "            d[key] = value.transpose(3, 2, 0, 1)\n",
    "        elif isinstance(value, dict):\n",
    "            transpose_4d_arrays(value)\n",
    "    return d\n",
    "\n",
    "new_data = transpose_4d_arrays(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print_structure(describe_structure(new_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(FINAL_DATABASE_PATH, new_data)\n",
    "print(\"Done writing the npy file\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workspace_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
