{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Well now that your long simulation is complete and your CSV file exported, let's get started with prepping this exported\n",
    "CSV to be imported to create the lookup table!\n",
    "\n",
    "The library importer code has been made to work with a very specifically formatted CSV file. If you follow the exact testbench setup guidelines there will be minimal changes.\n",
    "\n",
    "If you made some crappy decisions like using a different setup notations than what were recommended let's play a game of Hide and seek. I hide and you seek professional help.\n",
    "\n",
    "I have provided instructions to make import easier with minor differences in setup, but it won't be guaranteed to work!\n",
    "\n",
    "Firstly, how should your exported CSV look? It should look exactly like shown [here](../../sample_files/MVE.csv). If it does not which could be the case for simulations run at corners other\n",
    "than `Nominal` below are the instructions on how to format it.\n",
    "\n",
    "1. If you see something which is not `Point,Test,Output,Nominal,Spec,Weight,Pass/Fail` or something similar at the first line delete anything before that.\n",
    "2. If you also notice that the main result is in a different column and not directly beside the `Output` column and there could additionally, be `Min` and `Max` column. We will run the script below to rearrange the rows.\n",
    "3. It is okay if your `Test` column does not match.\n",
    "4. Go to the last line of your CSV file. Make sure there are no blank lines. The list line should be your last data line.\n",
    "5. While eval errors are hard to spot in a large CSV file, they can sometimes be spotted at very end, with blank data columns instead of any data. You can copy a similar data point's data or rerun your simulation for that point. and enter the data. If you have multiple eval errors, resolve them and re-run simulations. **It is not recommended to remove the data points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# say if your main data for that corner resides in column 8\n",
    "col_idx_of_interest = 8\n",
    "with open('../../sample_files/data_out.csv', 'r') as f:\n",
    "    data = list(csv.reader(f))\n",
    "    print(\"Read the CSV file successfully\")\n",
    "\n",
    "with open ('../../sample_files/data_out_formatted.csv', 'w', newline='') as f:\n",
    "    csv_out_formatted = csv.writer(f, delimiter=',')\n",
    "    print(\"Created new CSV file for writing\")\n",
    "    row_idx = 0\n",
    "    for row in data:\n",
    "        if row[0].startswith('Parameters:'):\n",
    "            # insert any changes you would like to make for Parameters row, specially like\n",
    "            # making the keys compliant with the defaults of the library.\n",
    "            # ds, gs, length, sb\n",
    "        else:\n",
    "            csv_out_formatted.writerow([row[0], row[1], row[2], row[col_idx_of_interest], row[3], row[4], row[5]]) # you can skip the extra columns if you want\n",
    "        print(f\"Processed Row: {row_idx}\")\n",
    "        row_idx += 1\n",
    "print(\"New CSV file written successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since these demo jupyter notebooks are in different directory than the library and sometimes it might not be possible to install this library even if you have the dependencies, you can\n",
    "run these demo files from within this directory by using the following snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Append the path of your library to the system path\n",
    "sys.path.append(os.path.abspath(\"../../\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully you now have a compliant file to be imported! However, one last step is to setup the `config`. We do so using the following snippet.\n",
    "Make sure to provide the correct path appended with `conf.py` to the `write_config()` function. Everything depends on this file being at correct location.\n",
    "So if you are running it from this directory then `../../` will take you to the root directory of this repository. From there `../../analog_daddy` takes you to the\n",
    "correct folder. There you save a file `conf.py`. Hence the path is `../../analog_daddy/conf.py`.\n",
    "\n",
    "(I agree there could be a more user friendly way of dealing with the above config file situation but I do not want to make any major changes to my code.)\n",
    "\n",
    "What we essentially do with this program is to enter the PDK geometric limits, voltage limits as well as the keys in case you swayed away from the default naming conventions.\n",
    "If not you can simply click enter if you want to keep the default values displayed. This function tries it's best to verify and sanitize the input.\n",
    "\n",
    "After everything is done you should get a message `Configuration saved to conf.py!`. I encourage you to open this file in **Read-Only** mode and go through it for sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analog_daddy.write_config import write_config\n",
    "write_config(\"../../analog_daddy/conf.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phew! Now you are ready for import. Hopefully, there should not be any issues if you followed the instructions carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from analog_daddy.importer import process_data, nest_populated_dictionary, lists_to_arrays\n",
    "newx, newy = process_data('../../sample_files/GPDK45.csv')\n",
    "z_ext = lists_to_arrays(nest_populated_dictionary(newy,newx))\n",
    "# Make sure to add additional Information to the Array.\n",
    "z_ext['nmos_svt']['w'] = 32e-06 # 32 um\n",
    "z_ext['info'] = \"GPDK 45 nm\" # PDK Name\n",
    "z_ext['temperature'] = 27 # 27 C\n",
    "z_ext['corner'] = \"tt\" # Typical Typical\n",
    "z_ext['pmos_svt']['w'] = 32e-06 # 32 um\n",
    "# Once everything is done, save the arrays as numpy array and then save to npy file.\n",
    "np.save(\"../../sample_files/GPDK45.npy\",z_ext)\n",
    "print(\"Done writing the npy file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are done! Head over to [Usage Demo](./usage_demo.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
